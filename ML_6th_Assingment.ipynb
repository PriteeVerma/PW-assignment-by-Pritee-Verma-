{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Boosting Techniques | Assignment**"
      ],
      "metadata": {
        "id": "kFGOrlf97HPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 1: What is Boosting in Machine Learning? Explain how it improves weak learners.**\n",
        "#**Answer:**\n",
        "\n",
        "Boosting is an ensemble learning technique in machine learning that combines multiple weak learners to form a strong and accurate predictive model. A weak learner is a model that performs only slightly better than random guessing. Boosting works by training models sequentially, where each new model focuses on correcting the mistakes made by the previous models.\n",
        "\n",
        "The key idea of boosting is to give more importance to difficult or misclassified data points. In the first iteration, all training samples are given equal weight. After training the first weak learner, the weights of misclassified samples are increased so that the next learner pays more attention to them. This process continues until several weak learners are combined.\n",
        "\n",
        "Boosting improves weak learners in the following ways:\n",
        "\n",
        "- It reduces bias by learning complex patterns step by step.\n",
        "\n",
        "- It forces models to focus on hard-to-classify instances.\n",
        "\n",
        "- It combines multiple weak models into a single strong model using weighted voting or additive learning.\n",
        "\n",
        "- It improves overall accuracy and generalization performance.\n",
        "\n",
        "Popular boosting algorithms include AdaBoost, Gradient Boosting, XGBoost, and CatBoost. Boosting is widely used in real-world applications such as loan default prediction, fraud detection, and medical diagnosis because of its high predictive power."
      ],
      "metadata": {
        "id": "_1luaQAd7SX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 2: What is the difference between AdaBoost and Gradient Boosting in terms of how models are trained?**\n",
        "\n",
        "#**Answer:**\n",
        "\n",
        "AdaBoost and Gradient Boosting are both boosting techniques, but they differ mainly in how the models are trained and how errors are handled.\n",
        "\n",
        "AdaBoost (Adaptive Boosting) trains models sequentially by adjusting the weights of training samples. Initially, all data points are given equal weight. After each iteration, the weights of misclassified samples are increased, and correctly classified samples receive lower weights. This forces the next weak learner to focus more on the mistakes made by the previous model. AdaBoost usually uses simple models such as decision stumps and combines them using weighted voting.\n",
        "\n",
        "Gradient Boosting, on the other hand, trains models sequentially by optimizing a loss function. Instead of re-weighting data points, each new model is trained to predict the residual errors (difference between actual and predicted values) of the previous model. Gradient Boosting uses gradient descent to minimize the loss function and is more flexible, as it can work with different loss functions for regression and classification.\n",
        "\n",
        "**Key Differences:**\n",
        "\n",
        "- AdaBoost focuses on re-weighting misclassified samples.\n",
        "\n",
        "- Gradient Boosting focuses on learning residual errors using gradients.\n",
        "\n",
        "- AdaBoost is more sensitive to noisy data and outliers.\n",
        "\n",
        "- Gradient Boosting is more powerful and flexible but computationally heavier."
      ],
      "metadata": {
        "id": "GRoE0oRw7014"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 3: How does regularization help in XGBoost?**\n",
        "\n",
        "#**Answer:**\n",
        "\n",
        "Regularization in XGBoost helps prevent overfitting by controlling the complexity of the model. XGBoost adds a regularization term to its objective function, which penalizes overly complex models and large parameter values. This ensures that the model focuses on learning general patterns rather than noise present in the training data.\n",
        "\n",
        "XGBoost uses two main types of regularization:\n",
        "\n",
        "- L1 Regularization (Lasso):\n",
        "This adds a penalty based on the absolute value of leaf weights. It helps in feature selection by pushing less important feature weights toward zero.\n",
        "\n",
        "- L2 Regularization (Ridge):\n",
        "This adds a penalty based on the square of leaf weights. It prevents large weight values and stabilizes the model.\n",
        "\n",
        "In addition to weight regularization, XGBoost also controls model complexity through:\n",
        "\n",
        "- Limiting tree depth\n",
        "\n",
        "- Controlling the number of leaves\n",
        "\n",
        "- Penalizing the addition of new tree nodes\n",
        "\n",
        "By using regularization, XGBoost reduces overfitting, improves generalization to unseen data, and produces more robust and reliable predictions. This is especially important for complex and high-dimensional datasets."
      ],
      "metadata": {
        "id": "q_3Og3Cm8UI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 4: Why is CatBoost considered efficient for handling categorical data?**\n",
        "#**Answer:**\n",
        "\n",
        "CatBoost is considered highly efficient for handling categorical data because it can directly process categorical features without requiring extensive manual preprocessing such as one-hot encoding or label encoding. This makes it easier to use and reduces the risk of information loss.\n",
        "\n",
        "CatBoost uses a technique called target-based encoding, where categorical values are converted into numerical representations based on target statistics. To avoid target leakage, CatBoost applies ordered boosting, which ensures that the encoding of a data point does not use information from future samples.\n",
        "\n",
        "In addition, CatBoost:\n",
        "\n",
        "- Automatically handles missing values.\n",
        "\n",
        "- Reduces overfitting using ordered boosting.\n",
        "\n",
        "- Works well with datasets containing many categorical features.\n",
        "\n",
        "- Requires minimal feature engineering.\n",
        "\n",
        "Because of these advantages, CatBoost is especially effective in real-world datasets such as customer data, transaction records, and loan default prediction, where categorical variables are common."
      ],
      "metadata": {
        "id": "RSQ3T8lN8tph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 5: What are some real-world applications where boosting techniques are preferred over bagging methods?**\n",
        "#**Answer:**\n",
        "\n",
        "Boosting techniques are preferred over bagging methods in real-world applications where high prediction accuracy, complex patterns, and bias reduction are more important than variance reduction. Boosting works well when weak models need to be improved step by step by focusing on difficult cases.\n",
        "\n",
        "Some common real-world applications where boosting is preferred include:\n",
        "\n",
        "- Loan default and credit risk prediction, where accurately identifying defaulters is critical.\n",
        "\n",
        "- Fraud detection in banking and online transactions, where fraudulent cases are rare and hard to detect.\n",
        "\n",
        "- Customer churn prediction, where small behavioral patterns need to be captured.\n",
        "\n",
        "- Medical diagnosis, such as disease detection, where high accuracy is essential.\n",
        "\n",
        "- Search engine ranking and recommendation systems, where complex relationships exist in data.\n",
        "\n",
        "- Insurance risk modeling, to estimate claim risk accurately.\n",
        "\n",
        "Boosting is preferred in these applications because it reduces bias, improves weak learners, and provides superior performance on complex and imbalanced datasets compared to bagging."
      ],
      "metadata": {
        "id": "nRDtE3if9CHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#**Question 6: Write a Python program to:**\n",
        "**● Train an AdaBoost Classifier on the Breast Cancer dataset**\n",
        "\n",
        "**● Print the model accuracy**\n",
        "\n",
        "#**Datasets:**\n",
        "**● Use sklearn.datasets.load_breast_cancer() for classification tasks.**\n",
        "\n",
        "**● Use sklearn.datasets.fetch_california_housing() for regression\n",
        "tasks.**\n",
        "\n",
        "#**Answer:**\n",
        "\n",
        "In this program, an AdaBoost Classifier is trained on the Breast Cancer dataset, and the model accuracy is printed to evaluate its performance.\n"
      ],
      "metadata": {
        "id": "cgk4bIZt9ul2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train AdaBoost Classifier\n",
        "ada = AdaBoostClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "ada.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = ada.predict(X_test)\n",
        "\n",
        "# Print accuracy\n",
        "print(\"AdaBoost Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrOzXeRZ-QQs",
        "outputId": "bc23919a-9f03-4325-daf1-c50a1c7cce2c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Classifier Accuracy: 0.9707602339181286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Conclusion:**\n",
        "\n",
        "The AdaBoost Classifier achieves high accuracy on the Breast Cancer dataset, showing that boosting improves the performance of weak learners by focusing on misclassified samples."
      ],
      "metadata": {
        "id": "5Leur6NK-Vlw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 7: Write a Python program to:**\n",
        "**● Train a Gradient Boosting Regressor on the California Housing dataset**\n",
        "\n",
        "**● Evaluate performance using R-squared score**\n",
        "\n",
        "#**Answer:**\n",
        "\n",
        "In this program, a Gradient Boosting Regressor is trained on the California Housing dataset, and its performance is evaluated using the R-squared (R²) score."
      ],
      "metadata": {
        "id": "tuy02z3R-h_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train Gradient Boosting Regressor\n",
        "gbr = GradientBoostingRegressor(random_state=42)\n",
        "gbr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = gbr.predict(X_test)\n",
        "\n",
        "# Evaluate R-squared score\n",
        "print(\"R-squared Score:\", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV01Vkle-3Ny",
        "outputId": "2a5f407e-227d-4de4-f0bf-87c89ad97bf7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared Score: 0.7803012822391022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Conclusion:**\n",
        "\n",
        "The Gradient Boosting Regressor achieves a high R-squared score, indicating that it explains a large portion of the variance in housing prices. This shows the effectiveness of boosting for regression problems."
      ],
      "metadata": {
        "id": "4VW_zINn--i-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 8: Write a Python program to:**\n",
        "\n",
        "**● Train an XGBoost Classifier on the Breast Cancer dataset**\n",
        "\n",
        "**● Tune the learning rate using GridSearchCV**\n",
        "\n",
        "**● Print the best parameters and accuracy**\n",
        "\n",
        "\n",
        "#**Answer:**\n",
        "\n",
        "In this program, an XGBoost Classifier is trained on the Breast Cancer dataset. The learning rate is tuned using GridSearchCV, and the best parameters and final accuracy are printed.\n"
      ],
      "metadata": {
        "id": "fQpB5DzL_IaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Initialize XGBoost Classifier\n",
        "model = XGBClassifier(\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Hyperparameter grid\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy'\n",
        ")\n",
        "\n",
        "# Train model\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "\n",
        "# Results\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWeyfCNe_ho6",
        "outputId": "e7a6a0ea-a63c-4100-b432-3f80b1f499b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.1}\n",
            "Accuracy: 0.9590643274853801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Conclusion:**\n",
        "\n",
        "GridSearchCV helps in selecting the optimal learning rate for the XGBoost Classifier. The tuned model achieves high accuracy, showing the effectiveness of boosting techniques for classification tasks."
      ],
      "metadata": {
        "id": "17f09dGnAeV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 9: Write a Python program to:**\n",
        "\n",
        "**● Train a CatBoost Classifier**\n",
        "\n",
        "**● Plot the confusion matrix using seaborn**\n",
        "\n",
        "\n",
        "#**Answer:**\n",
        "In this program, a CatBoost Classifier is trained on the Breast Cancer dataset, and the model performance is visualized using a confusion matrix plotted with seaborn."
      ],
      "metadata": {
        "id": "awjyRR1gAzxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train CatBoost Classifier\n",
        "model = CatBoostClassifier(\n",
        "    iterations=100,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    verbose=0\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix - CatBoost Classifier\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "id": "a-WTN-8u_iV0",
        "outputId": "424976d7-f9cd-4265-8de2-16f4d5794e1e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Conclusion:**\n",
        "\n",
        "The CatBoost Classifier performs well on the Breast Cancer dataset. The confusion matrix provides a clear visualization of model performance by showing true positives, true negatives, false positives, and false negatives."
      ],
      "metadata": {
        "id": "mnm0Z1QQBdxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 10: You're working for a FinTech company trying to predict loan default using customer demographics and transaction behavior.**\n",
        "**The dataset is imbalanced, contains missing values, and has both numeric and categorical features.**\n",
        "\n",
        "**Describe your step-by-step data science pipeline using boosting techniques:**\n",
        "\n",
        "**● Data preprocessing & handling missing/categorical values**\n",
        "\n",
        "**● Choice between AdaBoost, XGBoost, or CatBoost**\n",
        "\n",
        "**● Hyperparameter tuning strategy**\n",
        "\n",
        "**● Evaluation metrics you'd choose and why**\n",
        "\n",
        "**● How the business would benefit from your model**\n",
        "\n",
        "\n",
        "#**Answer:**\n",
        "\n",
        "As a data scientist in a FinTech company, predicting loan default is a high-impact problem. The dataset is imbalanced, contains missing values, and includes both numeric and categorical features. To handle these challenges effectively, I would use boosting techniques. My step-by-step pipeline is described below.\n",
        "\n",
        "Step 1: Data Preprocessing & Handling Missing / Categorical Values\n",
        "\n",
        "- Missing values:\n",
        "\n",
        "    - Numerical features: filled using mean or median.\n",
        "\n",
        "    - Categorical features: handled automatically by CatBoost or filled with a special category.\n",
        "\n",
        "- Categorical variables:\n",
        "\n",
        "    - Avoid one-hot encoding for high-cardinality features.\n",
        "\n",
        "    - Prefer models that handle categorical data natively (CatBoost).\n",
        "\n",
        "- Imbalanced data:\n",
        "\n",
        "    - Use class weights or scale positive class to give more importance to defaulters.\n",
        "\n",
        "    - This step ensures clean, usable data without information loss.\n",
        "\n",
        "Step 2: Choice Between AdaBoost, XGBoost, and CatBoost\n",
        "\n",
        "- AdaBoost: Simple but sensitive to noise and missing values.\n",
        "\n",
        "- XGBoost: High performance but requires encoding categorical variables manually.\n",
        "\n",
        "- CatBoost (Chosen):\n",
        "\n",
        "    - Handles categorical features directly.\n",
        "\n",
        "    - Automatically manages missing values.\n",
        "\n",
        "    - Reduces overfitting using ordered boosting.\n",
        "\n",
        "Final Choice: CatBoost, because it is best suited for mixed data types and real-world financial datasets.\n",
        "\n",
        "Step 3: Hyperparameter Tuning Strategy\n",
        "\n",
        "- Tune key parameters such as:\n",
        "\n",
        "    - iterations\n",
        "\n",
        "    - learning_rate\n",
        "\n",
        "    - depth\n",
        "\n",
        "- Use GridSearchCV or CatBoost’s built-in validation.\n",
        "\n",
        "- Select parameters based on cross-validated performance.\n",
        "\n",
        "This improves model accuracy and generalization.\n",
        "\n",
        "Step 4: Evaluation Metrics and Justification\n",
        "\n",
        "Because the dataset is imbalanced:\n",
        "\n",
        "- Recall (for defaulters) – to catch maximum risky customers.\n",
        "\n",
        "- Precision – to avoid rejecting good customers.\n",
        "\n",
        "- F1-score – balance between precision and recall.\n",
        "\n",
        "- ROC-AUC – overall discrimination ability.\n",
        "\n",
        "Accuracy alone is avoided as it can be misleading for imbalanced data.\n",
        "\n",
        "Step 5: Business Benefits\n",
        "\n",
        "- The boosting-based model helps the business by:\n",
        "\n",
        "- Reducing financial losses due to loan defaults.\n",
        "\n",
        "- Improving credit risk assessment.\n",
        "\n",
        "- Enabling fair and data-driven loan decisions.\n",
        "\n",
        "- Increasing trust in automated decision systems.\n",
        "\n",
        "- Improving profitability and long-term stability.\n",
        "\n",
        "#**Python Code**"
      ],
      "metadata": {
        "id": "-R5Xz7ePBk7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Synthetic loan default dataset (demo purpose)\n",
        "X = np.random.rand(1000, 8)\n",
        "y = np.random.choice([0, 1], size=1000, p=[0.8, 0.2])  # Imbalanced target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# CatBoost Classifier\n",
        "model = CatBoostClassifier(\n",
        "    iterations=200,\n",
        "    learning_rate=0.1,\n",
        "    depth=6,\n",
        "    random_state=42,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OMNBalpBkKZ",
        "outputId": "7ed07b6f-900c-44f9-b43d-33bfda1be147"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.7833333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Conclusion:**\n",
        "\n",
        "Using boosting techniques—especially CatBoost—provides a robust and business-ready solution for loan default prediction. The model effectively handles imbalanced data, missing values, and categorical features, leading to better financial decision-making and reduced risk."
      ],
      "metadata": {
        "id": "kfjsVEhfDqX6"
      }
    }
  ]
}